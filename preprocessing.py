import os
import glob
import bs4 # HTML íƒœê·¸ ì •ì œìš© (BeautifulSoup)
from dotenv import load_dotenv

# --- ë¬¸ì„œ ë¡œë” ì„í¬íŠ¸ ---
from langchain_community.document_loaders import Docx2txtLoader, WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# ---- 0. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ----
load_dotenv() 

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âš ï¸ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    exit()
else:
    print("âœ… OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ.")

# ---- 1. ë°ì´í„° ë¡œë“œ (Load) ----
print("\n--- 1ë‹¨ê³„ ì‹œì‘: ë°ì´í„° ì†ŒìŠ¤ ë¡œë”© ---")

# [1-1] ë¡œì»¬ Docx íŒŒì¼ ë¡œë“œ
DATA_PATH = "./data_source"
pattern = os.path.join(DATA_PATH, "*.docx")
file_paths = glob.glob(pattern)

file_docs = []

if file_paths:
    print(f"ğŸ“‚ ë¡œì»¬: '{DATA_PATH}'ì—ì„œ {len(file_paths)}ê°œì˜ .docx íŒŒì¼ ë°œê²¬")
    for path in file_paths:
        try:
            loader = Docx2txtLoader(path)
            file_docs.extend(loader.load())
            print(f"   - [íŒŒì¼] ë¡œë“œ ì„±ê³µ: {os.path.basename(path)}")
        except Exception as e:
            print(f"   - [íŒŒì¼] âŒ ì—ëŸ¬: {os.path.basename(path)} ({e})")
else:
    print(f"ğŸ“‚ ë¡œì»¬: '{DATA_PATH}'ì— .docx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ê±´ë„ˆëœ€)")


# [1-2] ì›¹ì‚¬ì´íŠ¸ URL ë¡œë“œ (ìˆ˜ì •ë¨)
WEB_URL = "https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%9D%B4%ED%81%AC%EC%8A%A4%ED%8A%B8%EB%9D%BC_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98"

web_docs = []
try:
    print(f"ğŸŒ ì›¹: URL ë¡œë”© ì‹œì‘")
    loader = WebBaseLoader(
        web_paths=(WEB_URL,),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                "div", attrs={"id": ["mw-content-text", "bodyContent"]}
            )
        ),
    )
    web_docs = loader.load()

    # =========== [ì—¬ê¸°ë§Œ ì¶”ê°€í•˜ì‹œë©´ ë©ë‹ˆë‹¤!] ===========
    if web_docs:
        for doc in web_docs:
            # 1. ê¹¨ì§„ URL(%EC...)ì„ ê°€ì ¸ì™€ì„œ
            original_source = doc.metadata.get('source', '')
            # 2. í•œê¸€ë¡œ ë³µêµ¬(Decode)í•˜ê³ 
            decoded_source = unquote(original_source)
            # 3. ë‹¤ì‹œ ë®ì–´ì”Œì›ë‹ˆë‹¤.
            doc.metadata['source'] = decoded_source
            
        print(f"   - [ë³€í™˜ ì™„ë£Œ] ì¶œì²˜ê°€ í•œê¸€ë¡œ ë³€ê²½ë¨: {web_docs[0].metadata['source']}")
    # =================================================
        
except Exception as e:
    print(f"   - [ì›¹] âŒ ì—ëŸ¬ ë°œìƒ: {e}")


# [1-3] ë°ì´í„° í•©ì¹˜ê¸°
all_docs = file_docs + web_docs
print(f"\nğŸ“Š ì´ {len(all_docs)}ê°œì˜ ë¬¸ì„œ(Document)ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ---- 2. ë°ì´í„° ë¶„í•  (Split) ----
if all_docs:
    print("\n--- 2ë‹¨ê³„ ì‹œì‘: ë¬¸ì„œ ë¶„í•  ---")

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150,
        length_function=len,
    )
    chunks = text_splitter.split_documents(all_docs)

    print(f"ğŸ§© ì´ {len(chunks)}ê°œì˜ í…ìŠ¤íŠ¸ ì¡°ê°(Chunk) ìƒì„± ì™„ë£Œ")

    if chunks:
        print(f"   (ìƒ˜í”Œ) ì²« ë²ˆì§¸ ì¡°ê° ì¶œì²˜: {chunks[0].metadata.get('source')}")
        # ìƒ˜í”Œ ë‚´ìš©ì„ ì¡°ê¸ˆ ì¶œë ¥í•´ì„œ ì˜ ê°€ì ¸ì™”ëŠ”ì§€ í™•ì¸
        print(f"   (ìƒ˜í”Œ ë‚´ìš©) {chunks[0].page_content[:100]}...")
else:
    print("âš ï¸ ë¡œë“œëœ ë°ì´í„°ê°€ ì „í˜€ ì—†ì–´ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

# ---- 3. ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ (Embed & Store) ----
if chunks:
    print("\n--- 3ë‹¨ê³„ ì‹œì‘: ì„ë² ë”© ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ---")

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    print("ğŸ¤– OpenAI ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

    print("ğŸ“¦ FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘... (API í˜¸ì¶œ)")
    try:
        vectorstore = FAISS.from_documents(
            documents=chunks, 
            embedding=embeddings
        )
        
        VECTORSTORE_PATH = "faiss_index"
        vectorstore.save_local(VECTORSTORE_PATH)
        print(f"âœ… ì €ì¥ ì™„ë£Œ! ë²¡í„° ìŠ¤í† ì–´ê°€ '{VECTORSTORE_PATH}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ [ì˜¤ë¥˜] ì„ë² ë”©/ì €ì¥ ì‹¤íŒ¨: {e}")
else:
    print("âŒ ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ì¡°ê°ì´ ì—†ìŠµë‹ˆë‹¤.")